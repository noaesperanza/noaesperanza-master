import { useState, useRef, useEffect } from 'react'
import { openAIService, ChatMessage } from '../services/openaiService'
import { elevenLabsService } from '../services/elevenLabsService'
import { aiLearningService } from '../services/aiLearningService'
import { cleanTextForAudio } from '../utils/textUtils'

interface Message {
  id: string
  message: string
  sender: 'user' | 'noa'
  timestamp: Date
  options?: string[]
}

interface UseNoaChatProps {
  userMemory: any
  addNotification: (message: string, type?: 'info' | 'success' | 'warning' | 'error') => void
}

export const useNoaChat = ({ userMemory, addNotification }: UseNoaChatProps) => {
  const [messages, setMessages] = useState<Message[]>([])
  const [isTyping, setIsTyping] = useState(false)
  const [audioPlaying, setAudioPlaying] = useState(false)
  const currentAudioRef = useRef<HTMLAudioElement | null>(null)

  // Resposta real da NOA usando OpenAI
  const getNoaResponse = async (userMessage: string) => {
    setIsTyping(true)
    
    try {
      // Obter contexto de aprendizado da IA
      const learningContext = await aiLearningService.getLearningContext(userMessage)
      
      // Converte hist√≥rico para formato OpenAI com contexto do usu√°rio
      const systemContext = `Voc√™ √© N√¥a Esperanza, assistente m√©dica inteligente do Dr. Ricardo Valen√ßa.

${learningContext} 

INFORMA√á√ïES DO USU√ÅRIO:
- Nome: ${userMemory.name || 'N√£o informado'}
- √öltima visita: ${userMemory.lastVisit ? new Date(userMemory.lastVisit).toLocaleDateString('pt-BR') : 'Primeira vez'}

DIRETRIZES GERAIS:
- Seja sempre amig√°vel, profissional e emp√°tica
- Use o nome do usu√°rio quando souber
- Respeite sempre a √©tica m√©dica
- N√£o d√™ diagn√≥sticos, apenas orienta√ß√µes gerais
- Sugira consulta m√©dica quando necess√°rio
- Mantenha tom conversacional e acolhedor
- Se n√£o souber algo, seja honesta sobre suas limita√ß√µes
- Sempre termine suas respostas perguntando como pode ajudar ou oferecendo op√ß√µes
- Seja espec√≠fica sobre suas especialidades: neurologia, cannabis medicinal e nefrologia`

      const conversationHistory: ChatMessage[] = [
        { role: 'system', content: systemContext },
        ...messages
        .filter(msg => msg.sender === 'user' || msg.sender === 'noa')
        .map(msg => ({
          role: msg.sender === 'user' ? 'user' as const : 'assistant' as const,
          content: msg.message
        }))
          .slice(-8) // Mant√©m apenas as √∫ltimas 8 mensagens + contexto do sistema
      ]

      // Chama OpenAI para gerar resposta
      const response = await openAIService.getNoaResponse(userMessage, conversationHistory)
      
      // Op√ß√µes padr√£o para conversas gerais
      const defaultOptions = [
        'Avalia√ß√£o inicial',
        'Fazer uma pergunta sobre sa√∫de',
        'Como voc√™ est√°?'
      ]
      
      const noaMessage: Message = {
        id: crypto.randomUUID(),
        message: response,
        sender: 'noa',
        timestamp: new Date(),
        options: defaultOptions
      }
      
      setMessages(prev => [...prev, noaMessage])
      
      // üß† APRENDIZADO AUTOM√ÅTICO - IA aprende com a conversa
      aiLearningService.saveInteraction(userMessage, response, 'general')
      
      // ElevenLabs gera √°udio
      await playNoaAudioWithText(response)
      
    } catch (error) {
      console.error('Erro ao obter resposta da NOA:', error)
    } finally {
      setIsTyping(false)
    }
  }

  // Fun√ß√£o para tocar √°udio da NOA com texto sincronizado
  const playNoaAudioWithText = async (text: string) => {
    try {
      // Se j√° est√° tocando √°udio, n√£o toca outro
      if (audioPlaying) {
        return
      }
      
      // Para o √°udio atual se estiver tocando
      if (currentAudioRef.current) {
        currentAudioRef.current.pause()
        currentAudioRef.current = null
      }
      
      // Remove markdown e formata√ß√£o para o √°udio, preservando acentos
      const cleanText = cleanTextForAudio(text)

      const audioResponse = await elevenLabsService.textToSpeech(cleanText)
      
      // Cria e toca o √°udio
      const audioBlob = new Blob([audioResponse.audio], { type: 'audio/mpeg' })
      const audioUrl = URL.createObjectURL(audioBlob)
      const audio = new Audio(audioUrl)
      
      // Armazena refer√™ncia do √°udio atual
      currentAudioRef.current = audio
      setAudioPlaying(true)

      audio.play().then(() => {
        console.log('üéµ √Åudio tocando com sucesso!')
      }).catch(error => {
        console.log('‚ùå Erro ao tocar √°udio:', error)
        setAudioPlaying(false)
      })

      // Limpa a URL e refer√™ncia ap√≥s tocar
      audio.onended = () => {
        URL.revokeObjectURL(audioUrl)
        currentAudioRef.current = null
        setAudioPlaying(false)
      }
      
      // Limpa refer√™ncia se houver erro
      audio.onerror = () => {
        URL.revokeObjectURL(audioUrl)
        currentAudioRef.current = null
        setAudioPlaying(false)
      }

    } catch (error) {
      console.log('‚ùå Erro ao gerar √°udio da NOA:', error)
      setAudioPlaying(false)
    }
  }

  const handleSendMessage = (messageText: string) => {
    if (!messageText.trim()) return

    // Adiciona mensagem do usu√°rio
    const userMessage: Message = {
      id: crypto.randomUUID(),
      message: messageText,
      sender: 'user',
      timestamp: new Date()
    }

    setMessages(prev => [...prev, userMessage])

    // Obt√©m resposta real da NOA
    getNoaResponse(messageText)
  }

  return {
    messages,
    isTyping,
    audioPlaying,
    currentAudioRef,
    handleSendMessage,
    playNoaAudioWithText
  }
}
