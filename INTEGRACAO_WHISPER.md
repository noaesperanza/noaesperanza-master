# ğŸ¤ INTEGRAÃ‡ÃƒO WHISPER - PRÃ“XIMOS PASSOS

## âœ… Arquivos Criados

1. **`src/hooks/useWhisperSTT.ts`** - Hook Whisper pronto
2. **`GUIA_SPEECH_TO_TEXT.md`** - Guia completo

## ğŸ”§ Como Integrar no Chat

### OpÃ§Ã£o 1: Substituir Completamente (Recomendado)

Modifique `NoaConversationalInterface.tsx`:

```typescript
// ADICIONAR NO TOPO
import { useWhisperSTT } from '../hooks/useWhisperSTT'

// SUBSTITUIR O CÃ“DIGO DE RECONHECIMENTO DE VOZ
const whisper = useWhisperSTT({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  language: 'pt',
  temperature: 0.2
})

// SUBSTITUIR toggleListening
const toggleListening = useCallback(async () => {
  if (whisper.isRecording) {
    const result = await whisper.stopRecording()
    if (result?.text) {
      sendMessage(result.text, { preferVoice: true })
    }
  } else {
    await whisper.startRecording()
  }
}, [whisper, sendMessage])

// ATUALIZAR ESTADO DO BOTÃƒO
const isListening = whisper.isRecording || whisper.isTranscribing
```

### OpÃ§Ã£o 2: HÃ­brida (Fallback)

Use Whisper como primÃ¡rio, Web Speech API como fallback:

```typescript
const [useWhisperMode, setUseWhisperMode] = useState(true)

const whisper = useWhisperSTT({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  language: 'pt'
})

const toggleListening = useCallback(async () => {
  if (useWhisperMode) {
    // Usar Whisper
    if (whisper.isRecording) {
      const result = await whisper.stopRecording()
      if (result?.text) {
        sendMessage(result.text, { preferVoice: true })
      }
    } else {
      await whisper.startRecording()
    }
  } else {
    // Fallback para Web Speech API (cÃ³digo atual)
    if (isListening) {
      stopListening()
    } else {
      startListening()
    }
  }
}, [useWhisperMode, whisper, isListening, startListening, stopListening, sendMessage])
```

---

## ğŸ“‹ Checklist de ImplementaÃ§Ã£o

- [ ] Importar `useWhisperSTT` no componente
- [ ] Inicializar hook com chave OpenAI
- [ ] Substituir `toggleListening` para usar Whisper
- [ ] Atualizar estado `isListening` para refletir Whisper
- [ ] Testar gravaÃ§Ã£o e transcriÃ§Ã£o
- [ ] Monitorar custos no painel OpenAI

---

## ğŸ¯ ModificaÃ§Ãµes NecessÃ¡rias

### Arquivo: `src/components/NoaConversationalInterface.tsx`

**Linhas a modificar:**

1. **Linha 1-10:** Adicionar import do Whisper
2. **Linha 175-338:** Substituir `startListening` e `stopListening`
3. **Linha 457-465:** Substituir `toggleListening`
4. **Linha 69:** Atualizar estado `isListening`

---

## ğŸ’¡ Dica

Para implementaÃ§Ã£o rÃ¡pida, posso fazer as modificaÃ§Ãµes automaticamente.

**Quer que eu faÃ§a a integraÃ§Ã£o completa agora?**

OpÃ§Ãµes:
1. âœ… **Substituir completamente** (melhor precisÃ£o)
2. âš ï¸ **HÃ­brida** (Whisper + fallback Web Speech)
3. â¸ï¸ **Deixar para depois**

Me diga qual opÃ§Ã£o prefere! ğŸš€
