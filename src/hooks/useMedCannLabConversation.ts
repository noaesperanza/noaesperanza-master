import { useCallback, useEffect, useMemo, useRef, useState } from 'react'
import { useAuth } from '../contexts/AuthContext'
import { NoaResidentAI, type AIResponse } from '../lib/noaResidentAI'
import { ConversationalIntent } from '../lib/medcannlab/types'

const sanitizeForSpeech = (text: string): string => {
  return text
    .replace(/\r?\n+/g, ' ')
    .replace(/[‚Ä¢‚óè‚ñ™Ô∏é‚ñ™]/g, ' item ')
    .replace(/N√¥a/gi, 'Noa')
    .replace(/Med\s*Cann\s*Lab/gi, 'Med Can Lab')
    .replace(/LGPD/gi, 'L G P D')
    .replace(/%/g, ' por cento ')
    .replace(/\s+/g, ' ')
    .trim()
}

export interface ConversationMessage {
  id: string
  role: 'user' | 'noa'
  content: string
  timestamp: Date
  intent?: ConversationalIntent
  metadata?: Record<string, unknown>
}

interface SendMessageOptions {
  preferVoice?: boolean
}

const createConversationId = () => {
  if (typeof crypto !== 'undefined' && typeof crypto.randomUUID === 'function') {
    return crypto.randomUUID()
  }
  return `conv-${Date.now()}-${Math.random().toString(36).slice(2)}`
}

const mapResponseToIntent = (response: AIResponse): ConversationalIntent => {
  const metadataIntent = typeof response.metadata?.intent === 'string'
    ? response.metadata.intent
    : undefined

  if (metadataIntent && ['CHECK_STATUS', 'GET_TRAINING_CONTEXT', 'MANAGE_SIMULATION', 'ACCESS_LIBRARY', 'IMRE_ANALYSIS', 'SMALL_TALK', 'FOLLOW_UP', 'HELP', 'UNKNOWN'].includes(metadataIntent)) {
    return metadataIntent as ConversationalIntent
  }

  if (response.type === 'assessment') return 'IMRE_ANALYSIS'
  if (response.type === 'error') return 'UNKNOWN'

  return 'FOLLOW_UP'
}

const ensureDate = (value: Date | string | undefined) => {
  if (!value) return new Date()
  return value instanceof Date ? value : new Date(value)
}

const detectFollowUpQuestion = (text: string) => {
  if (!text) return false
  const normalized = text.toLowerCase()
  if (normalized.includes('?')) return true
  const questionHints = [
    /pode me dizer/,
    /pode informar/,
    /pode detalhar/,
    /me fale/,
    /me conte/,
    /qual (√©|seria)/,
    /como est[a√°]/,
    /quer continuar/,
    /pode atualizar/,
    /pode listar/,
    /me descreva/,
    /me informe/,
    /preciso que/,
    /pode confirmar/,
    /me responda/
  ]
  return questionHints.some(pattern => pattern.test(normalized))
}

interface SpeechQueueState {
  messageId: string
  fullContent: string
  sanitized: string
  displayIndex: number
  cancelled: boolean
  timer?: number
  requestImmediateReply?: boolean
}

interface NoaCommandDetail {
  type: 'navigate-section' | 'navigate-route' | 'show-prescription' | 'filter-patients'
  target: string
  label?: string
  fallbackRoute?: string
  payload?: Record<string, any>
  rawMessage: string
  source: 'voice' | 'text'
  timestamp: string
}

type VoiceNavigationCommand = {
  id: string
  type: 'navigate-section' | 'navigate-route' | 'show-prescription' | 'filter-patients'
  target: string
  label: string
  patterns: RegExp[]
  fallbackRoute?: string
  payload?: Record<string, any>
}

export const useMedCannLabConversation = () => {
  const { user } = useAuth()
  const residentRef = useRef<NoaResidentAI | null>(null)
  const conversationIdRef = useRef<string>(createConversationId())
  const [messages, setMessages] = useState<ConversationMessage[]>([])
  const [hasShownWelcome, setHasShownWelcome] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [lastIntent, setLastIntent] = useState<ConversationalIntent | null>(null)
  const [error, setError] = useState<string | null>(null)
  const [usedEndpoints, setUsedEndpoints] = useState<string[]>([])

  // Inicializar IA apenas quando houver um usu√°rio logado
  useEffect(() => {
    if (user && !residentRef.current) {
      try {
        residentRef.current = new NoaResidentAI()
        console.log('‚úÖ IA Residente inicializada para:', user.email)

        // Adicionar mensagem de boas-vindas apenas uma vez
        if (!hasShownWelcome && messages.length === 0) {
          const welcomeMessage: ConversationMessage = {
            id: 'welcome',
            role: 'noa',
            content: 'Sou N√¥a Esperanza. Apresente-se tamb√©m e diga o que trouxe voc√™ aqui? Voc√™ pode utilizar o chat aqui embaixo √† direita para responder ou pedir ajuda. Bons ventos s√≥prem.',
            timestamp: new Date(),
            intent: 'HELP'
          }
          setMessages([welcomeMessage])
          setHasShownWelcome(true)
        }
      } catch (error) {
        console.error('‚ùå Erro ao inicializar IA Residente:', error)
        setError('Erro ao inicializar IA residente. Tente recarregar a p√°gina.')
      }
    } else if (!user && residentRef.current) {
      // Limpar IA quando usu√°rio fizer logout
      residentRef.current = null
      setHasShownWelcome(false)
      setMessages([])
    }
  }, [user, hasShownWelcome, messages.length])

  const conversationId = useMemo(() => conversationIdRef.current, [])
  const lastSpokenMessageRef = useRef<string | null>(null)
  const voicesRef = useRef<SpeechSynthesisVoice[]>([])
  const speechEnabledRef = useRef(true)
  const speechQueueRef = useRef<SpeechQueueState | null>(null)
  const [voicesReady, setVoicesReady] = useState(false)
  const voiceNavigationCommandsRef = useRef<VoiceNavigationCommand[]>([
    {
      id: 'library-section',
      type: 'navigate-section',
      target: 'admin-upload',
      label: 'Biblioteca Compartilhada',
      fallbackRoute: '/app/library',
      patterns: [
        /biblioteca compartilhada/,
        /abrir biblioteca/,
        /abrir a biblioteca/,
        /base de conhecimento/,
        /acessar biblioteca/,
        /acessar a biblioteca/
      ]
    },
    {
      id: 'renal-section',
      type: 'navigate-section',
      target: 'admin-renal',
      label: 'Fun√ß√£o Renal',
      patterns: [
        /funcao renal/,
        /fun√ß√£o renal/,
        /abrir funcao renal/,
        /abrir fun√ß√£o renal/
      ]
    },
    {
      id: 'attendance-section',
      type: 'navigate-section',
      target: 'atendimento',
      label: 'Atendimento',
      patterns: [
        /abrir atendimento/,
        /area de atendimento/,
        /√°rea de atendimento/,
        /ir para atendimento/,
        /fluxo de atendimento/
      ]
    },
    {
      id: 'agenda-section',
      type: 'navigate-section',
      target: 'agendamentos',
      label: 'Agenda',
      patterns: [
        /abrir agenda/,
        /minha agenda/,
        /agenda clinica/,
        /agenda da clinica/,
        /ver agenda/
      ]
    },
    {
      id: 'show-prescription',
      type: 'show-prescription',
      target: 'latest',
      label: 'Mostrar √∫ltima prescri√ß√£o',
      patterns: [
        /mostrar prescri[c√ß][a√£]o/,
        /mostrar a prescri[c√ß][a√£]o/,
        /abrir prescri[c√ß][a√£]o/,
        /ver prescri[c√ß][a√£]o/,
        /mostrar protocolo terap[e√™]utico/,
        /mostrar protocolo/,
        /onde est[a√°] a prescri[c√ß][a√£]o/,
        /quero ver a prescri[c√ß][a√£]o/
      ]
    },
    {
      id: 'filter-patients-active',
      type: 'filter-patients',
      target: 'active',
      label: 'Filtrar pacientes ativos',
      payload: { filter: 'active' },
      patterns: [
        /pacientes ativos/,
        /mostrar pacientes ativos/,
        /listar pacientes ativos/,
        /filtrar pacientes ativos/,
        /pacientes em atendimento/
      ]
    },
    {
      id: 'filter-patients-rio-bonito',
      type: 'filter-patients',
      target: 'clinic:rio-bonito',
      label: 'Pacientes Rio Bonito',
      payload: { clinic: 'rio bonito' },
      patterns: [
        /pacientes de rio bonito/,
        /pacientes da cl[i√≠]nica de rio bonito/,
        /filtrar rio bonito/,
        /mostrar (a )?cl[i√≠]nica de rio bonito/,
        /pacientes rio bonito/
      ]
    },
    {
      id: 'patients-section',
      type: 'navigate-section',
      target: 'pacientes',
      label: 'Pacientes',
      patterns: [
        /abrir pacientes/,
        /meus pacientes/,
        /lista de pacientes/,
        /area de pacientes/,
        /√°rea de pacientes/,
        /gestao de pacientes/
      ]
    },
    {
      id: 'reports-section',
      type: 'navigate-section',
      target: 'relatorios-clinicos',
      label: 'Relat√≥rios',
      patterns: [
        /abrir relatorios/,
        /relatorios clinicos/,
        /relat√≥rios cl√≠nicos/,
        /meus relatorios/,
        /area de relatorios/,
        /√°rea de relat√≥rios/
      ]
    },
    {
      id: 'team-section',
      type: 'navigate-section',
      target: 'chat-profissionais',
      label: 'Equipe Cl√≠nica',
      patterns: [
        /abrir equipe/,
        /equipe clinica/,
        /equipe cl√≠nica/,
        /chat clinico/,
        /chat cl√≠nico/,
        /colaboracao clinica/,
        /colabora√ß√£o cl√≠nica/
      ]
    },
    {
      id: 'knowledge-route',
      type: 'navigate-route',
      target: '/app/library',
      label: 'Base de Conhecimento',
      patterns: [
        /base cientifica/,
        /base cient√≠fica/,
        /base de conhecimento/,
        /biblioteca cientifica/,
        /biblioteca cient√≠fica/
      ]
    }
  ])

  const updateMessageContent = useCallback((messageId: string, content: string) => {
    setMessages(prev => {
      let changed = false
      const next = prev.map(message => {
        if (message.id === messageId) {
          if (message.content === content) {
            return message
          }
          changed = true
          return { ...message, content }
        }
        return message
      })
      return changed ? next : prev
    })
  }, [setMessages])

  const stopSpeech = useCallback(() => {
    const queue = speechQueueRef.current
    if (queue) {
      queue.cancelled = true
      if (queue.timer) {
        window.clearTimeout(queue.timer)
        queue.timer = undefined
      }
      updateMessageContent(queue.messageId, queue.fullContent)
      speechQueueRef.current = null
    }

    if (typeof window !== 'undefined' && 'speechSynthesis' in window) {
      window.speechSynthesis.cancel()
    }
    setIsSpeaking(false)
  }, [updateMessageContent])

  useEffect(() => {
    const handleSoundToggle = (event: Event) => {
      const custom = event as CustomEvent<{ enabled?: boolean }>
      if (typeof custom.detail?.enabled === 'boolean') {
        speechEnabledRef.current = custom.detail.enabled
        if (!custom.detail.enabled) {
          stopSpeech()
        }
      }
    }

    window.addEventListener('noaSoundToggled', handleSoundToggle as EventListener)
    return () => window.removeEventListener('noaSoundToggled', handleSoundToggle as EventListener)
  }, [stopSpeech])

  useEffect(() => {
    if (typeof window === 'undefined' || !('speechSynthesis' in window)) {
      return
    }

    const populateVoices = () => {
      const available = window.speechSynthesis.getVoices()
      if (available && available.length > 0) {
        voicesRef.current = available
        setVoicesReady(true)
      }
    }

    populateVoices()
    window.speechSynthesis.onvoiceschanged = populateVoices

    return () => {
      if (window.speechSynthesis.onvoiceschanged === populateVoices) {
        window.speechSynthesis.onvoiceschanged = null
      }
    }
  }, [])

  useEffect(() => {
    const handleChatClosed = () => stopSpeech()
    window.addEventListener('noaChatClosed', handleChatClosed)
    const handleExternalStop = () => stopSpeech()
    window.addEventListener('noaStopSpeech', handleExternalStop)
    return () => {
      window.removeEventListener('noaChatClosed', handleChatClosed)
      window.removeEventListener('noaStopSpeech', handleExternalStop)
    }
  }, [stopSpeech])

  const normalizeCommandText = useCallback((text: string) => {
    return text
      .normalize('NFD')
      .replace(/[\u0300-\u036f]/g, '')
      .toLowerCase()
  }, [])

  const detectVoiceNavigationCommand = useCallback(
    (text: string): VoiceNavigationCommand | null => {
      const normalized = normalizeCommandText(text)
      const commands = voiceNavigationCommandsRef.current

      for (const command of commands) {
        if (command.patterns.some(pattern => pattern.test(normalized))) {
          return command
        }
      }

      return null
    },
    [normalizeCommandText]
  )

  const dispatchVoiceNavigationCommand = useCallback(
    (command: VoiceNavigationCommand, rawMessage: string, source: 'voice' | 'text') => {
      const detail: NoaCommandDetail = {
        type: command.type,
        target: command.target,
        label: command.label,
        fallbackRoute: command.fallbackRoute,
        payload: command.payload,
        rawMessage,
        source,
        timestamp: new Date().toISOString()
      }

      try {
        window.dispatchEvent(new CustomEvent<NoaCommandDetail>('noaCommand', { detail }))
        console.log('üì° Comando de navega√ß√£o enviado para interface:', detail)
      } catch (error) {
        console.warn('‚ö†Ô∏è Falha ao despachar comando de navega√ß√£o da N√¥a:', error)
      }
    },
    []
  )

  useEffect(() => {
    if (messages.length === 0) return

    const lastMessage = messages[messages.length - 1]
    if (!lastMessage || lastMessage.role !== 'noa') return

    // Evitar falar mensagem de boas-vindas duplicada
    if (lastMessage.id === 'welcome' && lastSpokenMessageRef.current === 'welcome') return

    // Se j√° come√ßamos a processar este ID, n√£o reiniciar o efeito inteiro (evita loop com typewriter)
    // Mas se o conte√∫do final mudou significativamente ou a fala foi cancelada, podemos querer reconsiderar
    if (lastSpokenMessageRef.current === lastMessage.id) {
      return
    }

    const fullContent = (lastMessage.metadata as Record<string, any> | undefined)?.fullContent ?? lastMessage.content
    if (!fullContent) return

    if (!voicesReady && voicesRef.current.length === 0) {
      updateMessageContent(lastMessage.id, fullContent)
      setIsSpeaking(false)
      return
    }

    lastSpokenMessageRef.current = lastMessage.id

    if (!speechEnabledRef.current || typeof window === 'undefined' || !('speechSynthesis' in window)) {
      updateMessageContent(lastMessage.id, fullContent)
      setIsSpeaking(false)
      return
    }

    const sanitized = sanitizeForSpeech(fullContent)
    const requiresImmediateReply = detectFollowUpQuestion(fullContent)

    const queue: SpeechQueueState = {
      messageId: lastMessage.id,
      fullContent,
      sanitized,
      displayIndex: 0,
      cancelled: false,
      requestImmediateReply: requiresImmediateReply
    }
    speechQueueRef.current = queue

    // Typewriter effect
    const revealStep = () => {
      const current = speechQueueRef.current
      if (!current || current.cancelled || current.messageId !== lastMessage.id) return

      const chunkSize = Math.max(12, Math.round(current.fullContent.length / 60))
      current.displayIndex = Math.min(current.fullContent.length, current.displayIndex + chunkSize)
      updateMessageContent(current.messageId, current.fullContent.slice(0, current.displayIndex))

      if (current.displayIndex < current.fullContent.length) {
        current.timer = window.setTimeout(revealStep, 55)
      } else {
        current.timer = undefined
      }
    }
    revealStep()

    // Speech Synthesis
    const utterance = new SpeechSynthesisUtterance(sanitized.length > 0 ? sanitized : fullContent)
    utterance.lang = 'pt-BR'
    utterance.rate = 1.15
    utterance.volume = 0.93

    const voices = voicesRef.current
    if (voices && voices.length > 0) {
      const preferred = voices.filter(v => v.lang?.toLowerCase() === 'pt-br')
      const contralto = preferred.find(v => /contralto|grave|baixa|low|alto/i.test(v.name))
      const victoria = preferred.find(v => /vit[o√≥]ria/i.test(v.name))
      const nonSoprano = preferred.filter(v => !/soprano|aguda|high|tenor/i.test(v.name))
      const selectedVoice = contralto || victoria || nonSoprano.find(v => /bia|camila|carol|helo[i√≠]sa/i.test(v.name)) || nonSoprano[0] || preferred[0] || voices[0]
      if (selectedVoice) {
        utterance.voice = selectedVoice
        utterance.pitch = contralto ? 0.65 : victoria ? 0.75 : 0.78
      }
    }

    utterance.onstart = () => {
      setIsSpeaking(true)
      if (queue.requestImmediateReply) {
        const estimatedDelay = Math.min(Math.max(sanitized.length * 15, 600), 4000)
        window.dispatchEvent(new CustomEvent('noaImmediateListeningRequest', { detail: { delay: estimatedDelay } }))
      }
    }

    utterance.onend = () => {
      console.log('üîá S√≠ntese de voz finalizada')
      setIsSpeaking(false) // Garantir que isSpeaking mude para false
      const current = speechQueueRef.current
      if (current && current.messageId === lastMessage.id) {
        updateMessageContent(current.messageId, current.fullContent)
        speechQueueRef.current = null
      }
    }

    utterance.onerror = (err) => {
      console.error('‚ùå Erro na s√≠ntese:', err)
      setIsSpeaking(false)
      const current = speechQueueRef.current
      if (current && current.messageId === lastMessage.id) {
        updateMessageContent(current.messageId, current.fullContent)
        speechQueueRef.current = null
      }
    }

    // Iniciar ap√≥s delay para evitar conflito com UI
    const startSpeakingDelay = 800
    const speakTimeout = window.setTimeout(() => {
      if (!queue.cancelled && speechEnabledRef.current && window.speechSynthesis) {
        window.speechSynthesis.cancel()
        window.speechSynthesis.speak(utterance)
      }
    }, startSpeakingDelay)

    return () => {
      // S√ì cancelar se o ID da mensagem mudou de fato
      // Se for apenas um re-render do mesmo ID por causa do content, N√ÉO CANCELAR
    }
  }, [messages.length, voicesReady, updateMessageContent])


  // Removido: Auto-falar mensagem de boas-vindas duplicada
  // A mensagem de boas-vindas j√° √© falada pelo useEffect principal que processa todas as mensagens da N√¥a

  const sendMessage = useCallback(async (text: string, options: SendMessageOptions = {}) => {
    const trimmed = text.trim()
    if (!trimmed || isProcessing) return

    // Verificar se h√° usu√°rio logado
    if (!user) {
      setError('Por favor, fa√ßa login para usar a IA residente.')
      return
    }

    // Garantir que a IA esteja inicializada (tentar novamente se necess√°rio)
    if (!residentRef.current) {
      try {
        residentRef.current = new NoaResidentAI()
        console.log('‚úÖ IA Residente inicializada durante envio de mensagem')
      } catch (error) {
        console.error('‚ùå Erro ao inicializar IA Residente:', error)
        setError('IA residente n√£o inicializada. Aguarde um momento e tente novamente.')
        return
      }
    }

    setIsProcessing(true)
    setError(null)
    stopSpeech()

    let navigationCommand: VoiceNavigationCommand | null = null
    try {
      navigationCommand = detectVoiceNavigationCommand(trimmed)
      if (navigationCommand) {
        dispatchVoiceNavigationCommand(navigationCommand, trimmed, options.preferVoice ? 'voice' : 'text')
      }
    } catch (commandError) {
      console.warn('‚ö†Ô∏è Erro ao processar comando de navega√ß√£o local:', commandError)
    }

    const userMessage: ConversationMessage = {
      id: `user-${Date.now()}`,
      role: 'user',
      content: trimmed,
      timestamp: new Date()
    }

    setMessages(prev => [...prev, userMessage])

    try {
      console.log('üì® Processando mensagem para IA:', trimmed.substring(0, 50) + '...')
      const contextualizedMessage =
        navigationCommand && navigationCommand.label
          ? `${trimmed}\n\n[contexto_da_plataforma]: A navega√ß√£o para "${navigationCommand.label}" foi executada com sucesso na interface ativa.`
          : trimmed

      const response = await residentRef.current.processMessage(contextualizedMessage, user.id, user.email)
      console.log('‚úÖ Resposta da IA recebida:', response.content.substring(0, 100) + '...')

      const intent = mapResponseToIntent(response)
      const assistantMessage: ConversationMessage = {
        id: `noa-${Date.now()}`,
        role: 'noa',
        content: response.content, // Inicializar com o conte√∫do da resposta
        timestamp: ensureDate(response.timestamp),
        intent,
        metadata: {
          confidence: response.confidence,
          reasoning: response.reasoning,
          metadata: response.metadata,
          fullContent: response.content, // Mant√©m o conte√∫do completo para s√≠ntese de voz
          fromVoice: options.preferVoice ?? false,
          usedEndpoints: ['resident-ai']
        }
      }

      setMessages(prev => [...prev, assistantMessage])
      setLastIntent(intent)
      setUsedEndpoints(prev => [...prev, 'resident-ai'])
      console.log('üí¨ Mensagem da IA adicionada ao chat. Total de mensagens:', messages.length + 2)

      // Detectar se a IA mencionou ter criado um slide (mais robusto)
      const responseLower = response.content.toLowerCase()
      const slideKeywords = [
        'criei um slide', 'criei slide', 'slide criado', 'slide foi criado',
        'slide dispon√≠vel', 'slide est√° dispon√≠vel', 'novo slide', 'slide pronto',
        'slide gerado', 'slide foi gerado', 'prepara√ß√£o de slides', '√°rea de prepara√ß√£o de slides',
        'criar slide', 'gerar slide', 'slide na √°rea', 'na √°rea de prepara√ß√£o'
      ]

      const hasSlideMention = slideKeywords.some(keyword => responseLower.includes(keyword))

      // Tamb√©m verificar se h√° estrutura de slide na resposta (t√≠tulo, conte√∫do estruturado)
      const hasSlideStructure = response.content.match(/#+\s+[^\n]+\n/s) ||
        response.content.match(/\*\*[^\*]+\*\*/) ||
        response.content.match(/slide[:\s]+[^\n]+/i)

      if (hasSlideMention || hasSlideStructure) {
        // Extrair t√≠tulo do slide de v√°rias formas
        let slideTitle = `Slide ${new Date().toLocaleDateString('pt-BR')}`

        // Tentar extrair t√≠tulo de diferentes formatos
        const titlePatterns = [
          /slide[:\s]+"?([^"\n]+)"?/i,
          /t√≠tulo[:\s]+"?([^"\n]+)"?/i,
          /#+\s+([^\n]+)/,
          /\*\*([^\*]+)\*\*/,
          /slide\s+(\d+)[:\s]+([^\n]+)/i
        ]

        for (const pattern of titlePatterns) {
          const match = response.content.match(pattern)
          if (match) {
            slideTitle = match[1]?.trim() || match[2]?.trim() || slideTitle
            if (slideTitle && slideTitle.length > 3) break
          }
        }

        // Extrair conte√∫do do slide
        let slideContent = response.content

        // Se a resposta cont√©m estrutura de slide, tentar extrair melhor
        const contentPatterns = [
          /conte√∫do[:\s]+([^\n]+)/i,
          /slide[:\s]+[^\n]+\n([\s\S]+)/i,
          /#+\s+[^\n]+\n([\s\S]+)/,
        ]

        for (const pattern of contentPatterns) {
          const match = response.content.match(pattern)
          if (match && match[1]) {
            slideContent = match[1].trim()
            // Limitar conte√∫do a tamanho razo√°vel (primeiras 2000 caracteres)
            if (slideContent.length > 2000) {
              slideContent = slideContent.substring(0, 2000) + '...'
            }
            break
          }
        }

        // Se n√£o encontrou conte√∫do espec√≠fico, usar a resposta inteira (limitada)
        if (slideContent === response.content && slideContent.length > 500) {
          slideContent = slideContent.substring(0, 2000) + '...'
        }

        // Criar evento para notificar a cria√ß√£o do slide
        const slideEvent = new CustomEvent('slideCreated', {
          detail: {
            id: `slide_${Date.now()}`,
            title: slideTitle,
            content: slideContent,
            createdBy: 'ai'
          }
        })
        window.dispatchEvent(slideEvent)

        // Salvar slide no Supabase
        if (user?.id) {
          try {
            const { supabase } = await import('../lib/supabase')
            const { data, error } = await supabase
              .from('documents')
              .insert({
                title: slideTitle,
                content: slideContent,
                category: 'slides',
                file_type: 'slide',
                author: user.name || user.email,
                summary: slideContent.substring(0, 200) || '',
                tags: ['slide', 'aula', 'pedagogico', 'ai-generated'],
                keywords: ['slide', 'presentation', 'ai'],
                target_audience: ['student', 'professional'],
                isLinkedToAI: true
              })
              .select()
              .single()

            if (!error && data) {
              console.log('‚úÖ Slide criado pela IA e salvo no Supabase:', data.id)
              // Atualizar evento com ID real do banco e recarregar slides na interface
              const updatedEvent = new CustomEvent('slideCreated', {
                detail: {
                  id: data.id,
                  title: slideTitle,
                  content: slideContent,
                  createdBy: 'ai'
                }
              })
              window.dispatchEvent(updatedEvent)
            } else if (error) {
              console.error('‚ùå Erro ao salvar slide no Supabase:', error)
            }
          } catch (error) {
            console.error('‚ùå Erro ao salvar slide criado pela IA:', error)
          }
        }
      }

      if (response.type === 'error') {
        setError(response.content)
      }
    } catch (err) {
      console.error('[useMedCannLabConversation] Erro ao processar mensagem:', err)
      setError('Enfrentei um obst√°culo ao falar com a IA residente. Podemos tentar novamente em instantes.')
    } finally {
      setIsProcessing(false)
    }
  }, [isProcessing, user?.email, user?.id, stopSpeech])

  const triggerQuickCommand = useCallback((command: string) => {
    sendMessage(command)
  }, [sendMessage])

  const resetConversation = useCallback(() => {
    // S√≥ reiniciar se houver usu√°rio logado
    if (user) {
      residentRef.current = new NoaResidentAI()
    }
    conversationIdRef.current = createConversationId()
    setMessages([{
      id: 'welcome',
      role: 'noa',
      content: 'Conversa reiniciada. Vamos retomar? Posso monitorar o status do sistema ou abrir um novo protocolo cl√≠nico.',
      timestamp: new Date(),
      intent: 'HELP'
    }])
    setLastIntent(null)
    setUsedEndpoints([])
    setError(null)
  }, [user])

  return {
    conversationId,
    messages,
    isProcessing,
    lastIntent,
    error,
    usedEndpoints,
    isSpeaking,
    sendMessage,
    triggerQuickCommand,
    resetConversation
  }
}

